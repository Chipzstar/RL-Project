{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fOl6qnBpNypL"
   },
   "source": [
    "## **SET UP PYGAME ENVIRONMENT**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "OHSfDogYJBKp",
    "outputId": "d87d3d17-2882-4052-e6bc-c2f483a2a08e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pygame in c:\\users\\chiso\\anaconda3\\envs\\reinforcementlearning\\lib\\site-packages (2.0.1)\n"
     ]
    }
   ],
   "source": [
    "# ONLY NEED TO RUN ONCE\n",
    "import os\n",
    "#!git clone https://github.com/ntasfi/PyGame-Learning-Environment/\n",
    "# os.chdir(\"PyGame-Learning-Environment\")\n",
    "# print(f\"Current directory {os.getcwd()}\")\n",
    "# !pip install -e .\n",
    "# !pip install pygame\n",
    "# !pip install -q tensorflow\n",
    "# !pip install -q keras"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NWIMRIt-Rvug"
   },
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "CY2ZCy_JgImH",
    "outputId": "128964b4-1100-43e0-bf70-6f58fe09da51"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor Flow Version: 2.4.1\n",
      "Keras Version: 2.4.3\n",
      "\n",
      "Python 3.8.8 (default, Feb 24 2021, 15:54:32) [MSC v.1928 64 bit (AMD64)] Windows\n",
      "Pandas 1.2.3\n",
      "Scikit-Learn 0.24.1\n",
      "Num GPUs Available:  1\n",
      "GPU is available\n"
     ]
    }
   ],
   "source": [
    "import sys, os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sklearn as sk\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "from pprint import pprint\n",
    "import platform\n",
    "\n",
    "print(f\"Tensor Flow Version: {tf.__version__}\")\n",
    "print(f\"Keras Version: {keras.__version__}\")\n",
    "print()\n",
    "print(f\"Python {sys.version} {platform.system()}\")\n",
    "print(f\"Pandas {pd.__version__}\")\n",
    "print(f\"Scikit-Learn {sk.__version__}\")\n",
    "gpu = len(tf.config.list_physical_devices('GPU'))>0\n",
    "print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))\n",
    "print(\"GPU is\", \"available\" if gpu else \"NOT AVAILABLE\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9_ochpghVBCF"
   },
   "source": [
    "# Create Game"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "COZyA_SkX6N1"
   },
   "outputs": [],
   "source": [
    "class NaiveAgent:\n",
    "    def __init__(self, allowed_actions=[]):\n",
    "        self.moves = [\"up\", \"fall\"]\n",
    "        self.actions = allowed_actions\n",
    "        self.epsilon = 0.5\n",
    "        print(self.actions)\n",
    "\n",
    "    def pick_action(self):\n",
    "        action_index = np.random.randint(len(self.actions))\n",
    "        return self.actions[action_index], self.moves[action_index]\n",
    "\n",
    "    def go_up(self):\n",
    "        action = self.actions[0]\n",
    "        return action"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "WA3F-Zk_IqgM",
    "outputId": "7eb9fba0-a411-4e26-8e9f-d35e30e6a25f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pygame 2.0.1 (SDL 2.0.14, Python 3.8.8)\n",
      "Hello from the pygame community. https://www.pygame.org/contribute.html\n",
      "couldn't import doomish\n",
      "Couldn't import doom\n"
     ]
    }
   ],
   "source": [
    "# init\n",
    "from ple.games.pixelcopter import Pixelcopter\n",
    "from ple import PLE\n",
    "from ple.games import base\n",
    "game = Pixelcopter()\n",
    "env = PLE(game, fps=30, display_screen=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "WA3F-Zk_IqgM",
    "outputId": "7eb9fba0-a411-4e26-8e9f-d35e30e6a25f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[119, None]\n",
      "All actions [119, None]\n",
      "Frame: 0\n",
      "Current State:\n",
      "{'next_gate_block_bottom': 24,\n",
      " 'next_gate_block_top': 15,\n",
      " 'next_gate_dist_to_player': 34,\n",
      " 'player_dist_to_ceil': 7.0,\n",
      " 'player_dist_to_floor': 17.0,\n",
      " 'player_vel': 0,\n",
      " 'player_y': 24.0}\n",
      "New move: fall\n",
      "Reward: 0.0\n",
      "New State:\n",
      "{'next_gate_block_bottom': 24,\n",
      " 'next_gate_block_top': 15,\n",
      " 'next_gate_dist_to_player': 33.36,\n",
      " 'player_dist_to_ceil': 8.057023999999998,\n",
      " 'player_dist_to_floor': 15.942976000000002,\n",
      " 'player_vel': 0.05702400000000001,\n",
      " 'player_y': 24.057024}\n",
      "Frame: 1\n",
      "Current State:\n",
      "{'next_gate_block_bottom': 24,\n",
      " 'next_gate_block_top': 15,\n",
      " 'next_gate_dist_to_player': 33.36,\n",
      " 'player_dist_to_ceil': 8.057023999999998,\n",
      " 'player_dist_to_floor': 15.942976000000002,\n",
      " 'player_vel': 0.05702400000000001,\n",
      " 'player_y': 24.057024}\n",
      "New move: fall\n",
      "Reward: 0.0\n",
      "New State:\n",
      "{'next_gate_block_bottom': 24,\n",
      " 'next_gate_block_top': 15,\n",
      " 'next_gate_dist_to_player': 32.72,\n",
      " 'player_dist_to_ceil': 8.170501759999997,\n",
      " 'player_dist_to_floor': 15.829498240000003,\n",
      " 'player_vel': 0.11347776000000002,\n",
      " 'player_y': 24.170501759999997}\n",
      "Frame: 2\n",
      "Current State:\n",
      "{'next_gate_block_bottom': 24,\n",
      " 'next_gate_block_top': 15,\n",
      " 'next_gate_dist_to_player': 32.72,\n",
      " 'player_dist_to_ceil': 8.170501759999997,\n",
      " 'player_dist_to_floor': 15.829498240000003,\n",
      " 'player_vel': 0.11347776000000002,\n",
      " 'player_y': 24.170501759999997}\n",
      "New move: fall\n",
      "Reward: 0.0\n",
      "New State:\n",
      "{'next_gate_block_bottom': 24,\n",
      " 'next_gate_block_top': 15,\n",
      " 'next_gate_dist_to_player': 32.08,\n",
      " 'player_dist_to_ceil': 8.339868742399997,\n",
      " 'player_dist_to_floor': 15.660131257600003,\n",
      " 'player_vel': 0.16936698240000003,\n",
      " 'player_y': 24.339868742399997}\n",
      "Frame: 3\n",
      "Current State:\n",
      "{'next_gate_block_bottom': 24,\n",
      " 'next_gate_block_top': 15,\n",
      " 'next_gate_dist_to_player': 32.08,\n",
      " 'player_dist_to_ceil': 8.339868742399997,\n",
      " 'player_dist_to_floor': 15.660131257600003,\n",
      " 'player_vel': 0.16936698240000003,\n",
      " 'player_y': 24.339868742399997}\n",
      "New move: fall\n",
      "Reward: 0.0\n",
      "New State:\n",
      "{'next_gate_block_bottom': 24,\n",
      " 'next_gate_block_top': 15,\n",
      " 'next_gate_dist_to_player': 31.439999999999998,\n",
      " 'player_dist_to_ceil': 8.564566054975998,\n",
      " 'player_dist_to_floor': 15.435433945024002,\n",
      " 'player_vel': 0.22469731257600004,\n",
      " 'player_y': 24.564566054975998}\n",
      "Frame: 4\n",
      "Current State:\n",
      "{'next_gate_block_bottom': 24,\n",
      " 'next_gate_block_top': 15,\n",
      " 'next_gate_dist_to_player': 31.439999999999998,\n",
      " 'player_dist_to_ceil': 8.564566054975998,\n",
      " 'player_dist_to_floor': 15.435433945024002,\n",
      " 'player_vel': 0.22469731257600004,\n",
      " 'player_y': 24.564566054975998}\n",
      "New move: up\n",
      "Reward: 0.0\n",
      "New State:\n",
      "{'next_gate_block_bottom': 24,\n",
      " 'next_gate_block_top': 15,\n",
      " 'next_gate_dist_to_player': 30.799999999999997,\n",
      " 'player_dist_to_ceil': 8.232616394426238,\n",
      " 'player_dist_to_floor': 15.767383605573762,\n",
      " 'player_vel': -0.33194966054976016,\n",
      " 'player_y': 24.232616394426238}\n",
      "Frame: 5\n",
      "Current State:\n",
      "{'next_gate_block_bottom': 24,\n",
      " 'next_gate_block_top': 15,\n",
      " 'next_gate_dist_to_player': 30.799999999999997,\n",
      " 'player_dist_to_ceil': 8.232616394426238,\n",
      " 'player_dist_to_floor': 15.767383605573762,\n",
      " 'player_vel': -0.33194966054976016,\n",
      " 'player_y': 24.232616394426238}\n",
      "New move: fall\n",
      "Reward: 0.0\n",
      "New State:\n",
      "{'next_gate_block_bottom': 24,\n",
      " 'next_gate_block_top': 15,\n",
      " 'next_gate_dist_to_player': 30.159999999999997,\n",
      " 'player_dist_to_ceil': 7.961010230481975,\n",
      " 'player_dist_to_floor': 16.038989769518025,\n",
      " 'player_vel': -0.27160616394426257,\n",
      " 'player_y': 23.961010230481975}\n",
      "Frame: 6\n",
      "Current State:\n",
      "{'next_gate_block_bottom': 24,\n",
      " 'next_gate_block_top': 15,\n",
      " 'next_gate_dist_to_player': 30.159999999999997,\n",
      " 'player_dist_to_ceil': 7.961010230481975,\n",
      " 'player_dist_to_floor': 16.038989769518025,\n",
      " 'player_vel': -0.27160616394426257,\n",
      " 'player_y': 23.961010230481975}\n",
      "New move: fall\n",
      "Reward: 0.0\n",
      "New State:\n",
      "{'next_gate_block_bottom': 24,\n",
      " 'next_gate_block_top': 15,\n",
      " 'next_gate_dist_to_player': 29.519999999999996,\n",
      " 'player_dist_to_ceil': 7.749144128177154,\n",
      " 'player_dist_to_floor': 16.250855871822846,\n",
      " 'player_vel': -0.21186610230481992,\n",
      " 'player_y': 23.749144128177154}\n",
      "Frame: 7\n",
      "Current State:\n",
      "{'next_gate_block_bottom': 24,\n",
      " 'next_gate_block_top': 15,\n",
      " 'next_gate_dist_to_player': 29.519999999999996,\n",
      " 'player_dist_to_ceil': 7.749144128177154,\n",
      " 'player_dist_to_floor': 16.250855871822846,\n",
      " 'player_vel': -0.21186610230481992,\n",
      " 'player_y': 23.749144128177154}\n",
      "New move: fall\n",
      "Reward: 0.0\n",
      "New State:\n",
      "{'next_gate_block_bottom': 24,\n",
      " 'next_gate_block_top': 15,\n",
      " 'next_gate_dist_to_player': 28.879999999999995,\n",
      " 'player_dist_to_ceil': 7.596420686895382,\n",
      " 'player_dist_to_floor': 16.40357931310462,\n",
      " 'player_vel': -0.1527234412817717,\n",
      " 'player_y': 23.59642068689538}\n",
      "Frame: 8\n",
      "Current State:\n",
      "{'next_gate_block_bottom': 24,\n",
      " 'next_gate_block_top': 15,\n",
      " 'next_gate_dist_to_player': 28.879999999999995,\n",
      " 'player_dist_to_ceil': 7.596420686895382,\n",
      " 'player_dist_to_floor': 16.40357931310462,\n",
      " 'player_vel': -0.1527234412817717,\n",
      " 'player_y': 23.59642068689538}\n",
      "New move: fall\n",
      "Reward: 0.0\n",
      "New State:\n",
      "{'next_gate_block_bottom': 24,\n",
      " 'next_gate_block_top': 15,\n",
      " 'next_gate_dist_to_player': 28.239999999999995,\n",
      " 'player_dist_to_ceil': 7.502248480026427,\n",
      " 'player_dist_to_floor': 16.497751519973573,\n",
      " 'player_vel': -0.09417220686895397,\n",
      " 'player_y': 23.502248480026427}\n",
      "Frame: 9\n",
      "Current State:\n",
      "{'next_gate_block_bottom': 24,\n",
      " 'next_gate_block_top': 15,\n",
      " 'next_gate_dist_to_player': 28.239999999999995,\n",
      " 'player_dist_to_ceil': 7.502248480026427,\n",
      " 'player_dist_to_floor': 16.497751519973573,\n",
      " 'player_vel': -0.09417220686895397,\n",
      " 'player_y': 23.502248480026427}\n",
      "New move: up\n",
      "Reward: 1.0\n",
      "New State:\n",
      "{'next_gate_block_bottom': 24,\n",
      " 'next_gate_block_top': 15,\n",
      " 'next_gate_dist_to_player': 27.599999999999994,\n",
      " 'player_dist_to_ceil': 6.854617995226164,\n",
      " 'player_dist_to_floor': 17.145382004773836,\n",
      " 'player_vel': -0.6476304848002646,\n",
      " 'player_y': 22.854617995226164}\n",
      "Frame: 10\n",
      "Current State:\n",
      "{'next_gate_block_bottom': 24,\n",
      " 'next_gate_block_top': 15,\n",
      " 'next_gate_dist_to_player': 27.599999999999994,\n",
      " 'player_dist_to_ceil': 6.854617995226164,\n",
      " 'player_dist_to_floor': 17.145382004773836,\n",
      " 'player_vel': -0.6476304848002646,\n",
      " 'player_y': 22.854617995226164}\n",
      "New move: up\n",
      "Reward: 0.0\n",
      "New State:\n",
      "{'next_gate_block_bottom': 24,\n",
      " 'next_gate_block_top': 15,\n",
      " 'next_gate_dist_to_player': 26.959999999999994,\n",
      " 'player_dist_to_ceil': 5.659063815273903,\n",
      " 'player_dist_to_floor': 18.340936184726097,\n",
      " 'player_vel': -1.1955541799522622,\n",
      " 'player_y': 21.659063815273903}\n",
      "Frame: 11\n",
      "Current State:\n",
      "{'next_gate_block_bottom': 24,\n",
      " 'next_gate_block_top': 15,\n",
      " 'next_gate_dist_to_player': 26.959999999999994,\n",
      " 'player_dist_to_ceil': 5.659063815273903,\n",
      " 'player_dist_to_floor': 18.340936184726097,\n",
      " 'player_vel': -1.1955541799522622,\n",
      " 'player_y': 21.659063815273903}\n",
      "New move: up\n",
      "Reward: 0.0\n",
      "New State:\n",
      "{'next_gate_block_bottom': 24,\n",
      " 'next_gate_block_top': 15,\n",
      " 'next_gate_dist_to_player': 26.319999999999993,\n",
      " 'player_dist_to_ceil': 3.9210651771211644,\n",
      " 'player_dist_to_floor': 20.078934822878836,\n",
      " 'player_vel': -1.73799863815274,\n",
      " 'player_y': 19.921065177121164}\n",
      "Frame: 12\n",
      "Current State:\n",
      "{'next_gate_block_bottom': 24,\n",
      " 'next_gate_block_top': 15,\n",
      " 'next_gate_dist_to_player': 26.319999999999993,\n",
      " 'player_dist_to_ceil': 3.9210651771211644,\n",
      " 'player_dist_to_floor': 20.078934822878836,\n",
      " 'player_vel': -1.73799863815274,\n",
      " 'player_y': 19.921065177121164}\n",
      "New move: fall\n",
      "Reward: 0.0\n",
      "New State:\n",
      "{'next_gate_block_bottom': 24,\n",
      " 'next_gate_block_top': 15,\n",
      " 'next_gate_dist_to_player': 25.679999999999993,\n",
      " 'player_dist_to_ceil': 3.2574705253499516,\n",
      " 'player_dist_to_floor': 20.74252947465005,\n",
      " 'player_vel': -1.6635946517712124,\n",
      " 'player_y': 18.25747052534995}\n",
      "Frame: 13\n",
      "Current State:\n",
      "{'next_gate_block_bottom': 24,\n",
      " 'next_gate_block_top': 15,\n",
      " 'next_gate_dist_to_player': 25.679999999999993,\n",
      " 'player_dist_to_ceil': 3.2574705253499516,\n",
      " 'player_dist_to_floor': 20.74252947465005,\n",
      " 'player_vel': -1.6635946517712124,\n",
      " 'player_y': 18.25747052534995}\n",
      "New move: fall\n",
      "Reward: -5.0\n",
      "New State:\n",
      "{'next_gate_block_bottom': 24,\n",
      " 'next_gate_block_top': 15,\n",
      " 'next_gate_dist_to_player': 25.039999999999992,\n",
      " 'player_dist_to_ceil': 1.6675358200964503,\n",
      " 'player_dist_to_floor': 22.33246417990355,\n",
      " 'player_vel': -1.5899347052535002,\n",
      " 'player_y': 16.66753582009645}\n",
      "Frame: 14\n",
      "Current State:\n",
      "{'next_gate_block_bottom': 24,\n",
      " 'next_gate_block_top': 15,\n",
      " 'next_gate_dist_to_player': 25.039999999999992,\n",
      " 'player_dist_to_ceil': 1.6675358200964503,\n",
      " 'player_dist_to_floor': 22.33246417990355,\n",
      " 'player_vel': -1.5899347052535002,\n",
      " 'player_y': 16.66753582009645}\n",
      "GAME OVER!\n",
      "(48, 48, 3)\n"
     ]
    }
   ],
   "source": [
    "agent = NaiveAgent(allowed_actions=env.getActionSet())\n",
    "print(\"All actions\", agent.actions)\n",
    "reward = 0.0\n",
    "nb_frames = 100\n",
    "\n",
    "for i in range(nb_frames):\n",
    "    print(\"Frame:\", env.getFrameNumber())\n",
    "    state = env.getGameState()\n",
    "    print(\"Current State:\")\n",
    "    pprint(state)\n",
    "    if env.game_over():\n",
    "        print(\"GAME OVER!\")\n",
    "        break\n",
    "    action, move = agent.pick_action()\n",
    "    print(\"New move:\", move)\n",
    "    reward = env.act(action)\n",
    "    print(\"Reward:\", reward)\n",
    "    state = env.getGameState()\n",
    "    print(\"New State:\")\n",
    "    pprint(state)\n",
    "    env.saveScreen(f\"screenshots/Frame {i + 1}.png\")\n",
    "\n",
    "\n",
    "screenState = env.getScreenRGB()\n",
    "print(screenState.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "ReinforcementLearning.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "name": "python3",
   "language": "python",
   "display_name": "Python 3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}